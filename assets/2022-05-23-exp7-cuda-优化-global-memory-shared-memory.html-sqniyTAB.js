import{_ as a,o as t,c as n,e as s}from"./app-CoV9NwP4.js";const e={},o=s(`<h2 id="分析-test-gmem-cu-的性能变化来源" tabindex="-1"><a class="header-anchor" href="#分析-test-gmem-cu-的性能变化来源"><span>分析 <code>test_gmem.cu</code> 的性能变化来源</span></a></h2><div class="language-cpp line-numbers-mode" data-ext="cpp" data-title="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">stride_copy</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>dst<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>src<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">int</span> i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
  dst<span class="token punctuation">[</span>i <span class="token operator">*</span> STRIDE<span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i <span class="token operator">*</span> STRIDE<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="https://cdn.liblaf.me/img/2023/2023-02-24T050910Z.png" alt="Global Memory" tabindex="0" loading="lazy"><figcaption>Global Memory</figcaption></figure><h3 id="性能变化的主要来源是-gpu-的哪种机制引起的" tabindex="-1"><a class="header-anchor" href="#性能变化的主要来源是-gpu-的哪种机制引起的"><span>性能变化的主要来源是 GPU 的哪种机制引起的？</span></a></h3><p>访存合并机制.</p><h3 id="这种机制如何影响该程序的性能" tabindex="-1"><a class="header-anchor" href="#这种机制如何影响该程序的性能"><span>这种机制如何影响该程序的性能？</span></a></h3><p>在 DRAM, L2 cache, L1 cache 之间传输数据的最小单元为 1 sector = 32 Bytes. DRAM 访问总量为 <code>size * STRIDE * sizeof(float)</code> 与 <code>STRIDE</code> 成正比. 因此 <code>STRIDE</code> 越大, 程序访问的 transaction 个数越多, 且近似呈正比, 导致性能反比下降.</p><h3 id="是否有其他的硬件功能参与了该程序的执行过程-它们会如何影响该程序的执行效率" tabindex="-1"><a class="header-anchor" href="#是否有其他的硬件功能参与了该程序的执行过程-它们会如何影响该程序的执行效率"><span>是否有其他的硬件功能参与了该程序的执行过程, 它们会如何影响该程序的执行效率？</span></a></h3><p>cache. 顺序访问时, 数据会被缓存在 cache 中, 从而减少对 DRAM 的直接访问, 提升性能.</p><h2 id="分析-test-smem-cu-的性能变化来源" tabindex="-1"><a class="header-anchor" href="#分析-test-smem-cu-的性能变化来源"><span>分析 <code>test_smem.cu</code> 的性能变化来源</span></a></h2><div class="language-cpp line-numbers-mode" data-ext="cpp" data-title="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shmem</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">if</span> <span class="token expression"><span class="token punctuation">(</span>BITWIDTH <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">)</span></span></span>
  <span class="token keyword">volatile</span> __shared__ <span class="token keyword">uint16_t</span> shm<span class="token punctuation">[</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token keyword">volatile</span> <span class="token keyword">uint16_t</span> tmp<span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">elif</span> <span class="token expression"><span class="token punctuation">(</span>BITWIDTH <span class="token operator">==</span> <span class="token number">4</span><span class="token punctuation">)</span></span></span>
  <span class="token keyword">volatile</span> __shared__ <span class="token keyword">uint32_t</span> shm<span class="token punctuation">[</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token keyword">volatile</span> <span class="token keyword">uint32_t</span> tmp<span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">elif</span> <span class="token expression"><span class="token punctuation">(</span>BITWIDTH <span class="token operator">==</span> <span class="token number">8</span><span class="token punctuation">)</span></span></span>
  <span class="token keyword">volatile</span> __shared__ <span class="token keyword">uint64_t</span> shm<span class="token punctuation">[</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token keyword">volatile</span> <span class="token keyword">uint64_t</span> tmp<span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span>

  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> times<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    tmp <span class="token operator">=</span> shm<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> STRIDE<span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="https://cdn.liblaf.me/img/2023/2023-02-24T050933Z.png" alt="Shared Memory" tabindex="0" loading="lazy"><figcaption>Shared Memory</figcaption></figure><h3 id="固定-bitwidth-时-程序的性能变化来源于哪种硬件机制" tabindex="-1"><a class="header-anchor" href="#固定-bitwidth-时-程序的性能变化来源于哪种硬件机制"><span>固定 <code>BITWIDTH</code> 时, 程序的性能变化来源于哪种硬件机制？</span></a></h3><p>bank conflict.</p><h3 id="bitwidth-设置为-2-8-时性能变化的趋势相比于-bitwidth-设置为-4-时有什么不同之处-请解释" tabindex="-1"><a class="header-anchor" href="#bitwidth-设置为-2-8-时性能变化的趋势相比于-bitwidth-设置为-4-时有什么不同之处-请解释"><span><code>BITWIDTH</code> 设置为 2,8 时性能变化的趋势相比于 <code>BITWIDTH</code> 设置为 4 时有什么不同之处, 请解释.</span></a></h3><p><code>BITWIDTH</code> 设置为 4 时, bandwidth 随着 <code>STRIDE</code> 的增大而减小. <code>BITWIDTH</code> 设置为 2 时, <code>STRIDE</code> 为 1 和 2 时 bandwidth 几乎相等, 而后变化趋势与 <code>BITWIDTH</code> 设置为 4 时基本相同. <code>BITWIDTH</code> 设置为 8 时, <code>STRIDE</code> 为 16 和 32 时 bandwidth 几乎相等, 在这之前的变化趋势与 <code>BITWIDTH</code> 设置为 4 时基本相同.</p><p>当 <code>BITWIDTH</code> 为 4 时, 访存粒度为 4 Bytes = 1 bank, 相邻两个 thread 访问地址间隔为 <code>STRIDE</code> 个 bank. 当 <code>STRIDE</code> 为 1 时, 同一 wrap 内的 32 个 thread 访问了第一行内的 32 个 bank, 不存在 bank conflict. 当 <code>STRIDE</code> 为 2 时, <code>threadIdx.x</code> 与 <code>threadIdx.x + 16</code> 访问同一 bank, 发生 2-way bank conflict. 当 <code>STRIDE</code> 为 4 时, <code>threadIdx.x</code>, <code>threadIdx.x + 8</code>, <code>threadIdx.x + 16</code>, <code>threadIdx.x + 24</code> 访问同一个 bank, 发生 4-way bank conflict. 类似的, <code>STRIDE</code> 为 8 和 16 时分别发生 8-way bank conflict 和 16-way bank conflict.</p><p>当 <code>BITWIDTH</code> 为 2, <code>STRIDE</code> 为 1 时, 相邻两个 thread 访问同一个 bank, 发生 2-way bank conflict, 共访问 16 个 bank. 而 <code>STRIDE</code> 为 2 时, 虽然没有 bank conflict, 但需要访问 32 个 bank. 但由于每次访问仅使用 0.5 bank, 带宽为理论峰值的一半. 因此 <code>STRIDE</code> 为 1 或 2 时性能相近.</p><p>当 <code>BITWIDTH</code> 为 8, <code>STIRDE</code> 为 16 时, 相邻两个 thread 访存地址间隔为 128 Bytes, 恰为一行. 这意味着, 所有 thread 都访问 bank-0 和 bank-1, 发生 32-way bank conflict. 而当 <code>STRIDE</code> 为 32 时, 相邻两个 thread 访存地址间隔为 256 Bytes, 为两行, 此时所有 thread 仍都访问 bank-0 和 bank-1, 发生 32-way bank conflict. 因此 <code>STRIDE</code> 为 16 或 32 时性能相近.</p><h2 id="performance" tabindex="-1"><a class="header-anchor" href="#performance"><span>Performance</span></a></h2><h3 id="global-memory" tabindex="-1"><a class="header-anchor" href="#global-memory"><span>Global Memory</span></a></h3><table><thead><tr><th>Stride</th><th>Bandwidth (GB/s)</th></tr></thead><tbody><tr><td>1</td><td>530.015</td></tr><tr><td>2</td><td>182.471</td></tr><tr><td>4</td><td>91.9932</td></tr><tr><td>8</td><td>46.2866</td></tr></tbody></table><h3 id="shared-memory" tabindex="-1"><a class="header-anchor" href="#shared-memory"><span>Shared Memory</span></a></h3><table><thead><tr><th>Bitwidth</th><th>Stride</th><th>Bandwidth (GB/s)</th></tr></thead><tbody><tr><td>2</td><td>1</td><td>4258.05</td></tr><tr><td>2</td><td>2</td><td>4270.88</td></tr><tr><td>2</td><td>4</td><td>2149.69</td></tr><tr><td>2</td><td>8</td><td>831.405</td></tr><tr><td>2</td><td>16</td><td>427.135</td></tr><tr><td>2</td><td>32</td><td>215.022</td></tr><tr><td>4</td><td>1</td><td>8607.33</td></tr><tr><td>4</td><td>2</td><td>4315.77</td></tr><tr><td>4</td><td>4</td><td>2027.46</td></tr><tr><td>4</td><td>8</td><td>1012.86</td></tr><tr><td>4</td><td>16</td><td>504.37</td></tr><tr><td>4</td><td>32</td><td>251.766</td></tr><tr><td>8</td><td>1</td><td>8657.57</td></tr><tr><td>8</td><td>2</td><td>4339.44</td></tr><tr><td>8</td><td>4</td><td>2173.55</td></tr><tr><td>8</td><td>8</td><td>1087.65</td></tr><tr><td>8</td><td>16</td><td>544.069</td></tr><tr><td>8</td><td>32</td><td>544.068</td></tr></tbody></table>`,24),p=[o];function c(d,r){return t(),n("div",null,p)}const i=a(e,[["render",c],["__file","2022-05-23-exp7-cuda-优化-global-memory-shared-memory.html.vue"]]),u=JSON.parse('{"path":"/2022/course-work/hpc/2022-05-23-exp7-cuda-%E4%BC%98%E5%8C%96-global-memory-shared-memory.html","title":"exp7: CUDA 优化 (global memory, shared memory)","lang":"en-US","frontmatter":{"date":"2022-05-23T00:00:00.000Z","isOriginal":true,"category":["Course Work"],"tag":["CUDA","Introduction to High Performance Computing"],"title":"exp7: CUDA 优化 (global memory, shared memory)","description":"分析 test_gmem.cu 的性能变化来源 Global MemoryGlobal Memory 性能变化的主要来源是 GPU 的哪种机制引起的？ 访存合并机制. 这种机制如何影响该程序的性能？ 在 DRAM, L2 cache, L1 cache 之间传输数据的最小单元为 1 sector = 32 Bytes. DRAM 访问总量为 size ...","head":[["meta",{"property":"og:url","content":"https://blog.liblaf.me/2022/course-work/hpc/2022-05-23-exp7-cuda-%E4%BC%98%E5%8C%96-global-memory-shared-memory.html"}],["meta",{"property":"og:site_name","content":"Blog"}],["meta",{"property":"og:title","content":"exp7: CUDA 优化 (global memory, shared memory)"}],["meta",{"property":"og:description","content":"分析 test_gmem.cu 的性能变化来源 Global MemoryGlobal Memory 性能变化的主要来源是 GPU 的哪种机制引起的？ 访存合并机制. 这种机制如何影响该程序的性能？ 在 DRAM, L2 cache, L1 cache 之间传输数据的最小单元为 1 sector = 32 Bytes. DRAM 访问总量为 size ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.liblaf.me/img/2023/2023-02-24T050910Z.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-03-03T09:57:39.000Z"}],["meta",{"property":"article:author","content":"liblaf"}],["meta",{"property":"article:tag","content":"CUDA"}],["meta",{"property":"article:tag","content":"Introduction to High Performance Computing"}],["meta",{"property":"article:published_time","content":"2022-05-23T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-03-03T09:57:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"exp7: CUDA 优化 (global memory, shared memory)\\",\\"image\\":[\\"https://cdn.liblaf.me/img/2023/2023-02-24T050910Z.png\\",\\"https://cdn.liblaf.me/img/2023/2023-02-24T050933Z.png\\"],\\"datePublished\\":\\"2022-05-23T00:00:00.000Z\\",\\"dateModified\\":\\"2024-03-03T09:57:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"liblaf\\",\\"url\\":\\"https://liblaf.me\\",\\"email\\":\\"i@liblaf.me\\"}]}"]]},"headers":[{"level":2,"title":"分析 test_gmem.cu 的性能变化来源","slug":"分析-test-gmem-cu-的性能变化来源","link":"#分析-test-gmem-cu-的性能变化来源","children":[{"level":3,"title":"性能变化的主要来源是 GPU 的哪种机制引起的？","slug":"性能变化的主要来源是-gpu-的哪种机制引起的","link":"#性能变化的主要来源是-gpu-的哪种机制引起的","children":[]},{"level":3,"title":"这种机制如何影响该程序的性能？","slug":"这种机制如何影响该程序的性能","link":"#这种机制如何影响该程序的性能","children":[]},{"level":3,"title":"是否有其他的硬件功能参与了该程序的执行过程, 它们会如何影响该程序的执行效率？","slug":"是否有其他的硬件功能参与了该程序的执行过程-它们会如何影响该程序的执行效率","link":"#是否有其他的硬件功能参与了该程序的执行过程-它们会如何影响该程序的执行效率","children":[]}]},{"level":2,"title":"分析 test_smem.cu 的性能变化来源","slug":"分析-test-smem-cu-的性能变化来源","link":"#分析-test-smem-cu-的性能变化来源","children":[{"level":3,"title":"固定 BITWIDTH 时, 程序的性能变化来源于哪种硬件机制？","slug":"固定-bitwidth-时-程序的性能变化来源于哪种硬件机制","link":"#固定-bitwidth-时-程序的性能变化来源于哪种硬件机制","children":[]},{"level":3,"title":"BITWIDTH 设置为 2,8 时性能变化的趋势相比于 BITWIDTH 设置为 4 时有什么不同之处, 请解释.","slug":"bitwidth-设置为-2-8-时性能变化的趋势相比于-bitwidth-设置为-4-时有什么不同之处-请解释","link":"#bitwidth-设置为-2-8-时性能变化的趋势相比于-bitwidth-设置为-4-时有什么不同之处-请解释","children":[]}]},{"level":2,"title":"Performance","slug":"performance","link":"#performance","children":[{"level":3,"title":"Global Memory","slug":"global-memory","link":"#global-memory","children":[]},{"level":3,"title":"Shared Memory","slug":"shared-memory","link":"#shared-memory","children":[]}]}],"git":{"createdTime":1677217008000,"updatedTime":1709459859000,"contributors":[{"name":"liblaf","email":"30631553+liblaf@users.noreply.github.com","commits":4}]},"readingTime":{"minutes":2.77,"words":831},"filePathRelative":"2022/course-work/hpc/2022-05-23-exp7-cuda-优化-global-memory-shared-memory.md","localizedDate":"May 23, 2022","excerpt":"<h2>分析 <code>test_gmem.cu</code> 的性能变化来源</h2>\\n<div class=\\"language-cpp\\" data-ext=\\"cpp\\" data-title=\\"cpp\\"><pre class=\\"language-cpp\\"><code>__global__ <span class=\\"token keyword\\">void</span> <span class=\\"token function\\">stride_copy</span><span class=\\"token punctuation\\">(</span><span class=\\"token keyword\\">float</span> <span class=\\"token operator\\">*</span>dst<span class=\\"token punctuation\\">,</span> <span class=\\"token keyword\\">float</span> <span class=\\"token operator\\">*</span>src<span class=\\"token punctuation\\">)</span> <span class=\\"token punctuation\\">{</span>\\n  <span class=\\"token keyword\\">int</span> i <span class=\\"token operator\\">=</span> blockIdx<span class=\\"token punctuation\\">.</span>x <span class=\\"token operator\\">*</span> blockDim<span class=\\"token punctuation\\">.</span>x <span class=\\"token operator\\">+</span> threadIdx<span class=\\"token punctuation\\">.</span>x<span class=\\"token punctuation\\">;</span>\\n  dst<span class=\\"token punctuation\\">[</span>i <span class=\\"token operator\\">*</span> STRIDE<span class=\\"token punctuation\\">]</span> <span class=\\"token operator\\">=</span> src<span class=\\"token punctuation\\">[</span>i <span class=\\"token operator\\">*</span> STRIDE<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">;</span>\\n<span class=\\"token punctuation\\">}</span>\\n</code></pre></div>","autoDesc":true}');export{i as comp,u as data};
