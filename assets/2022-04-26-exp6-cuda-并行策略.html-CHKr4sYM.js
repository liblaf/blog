import{_ as e,o as a,c as o,e as t}from"./app-CoV9NwP4.js";const i={},r=t('<h2 id="performance" tabindex="-1"><a class="header-anchor" href="#performance"><span>Performance</span></a></h2><figure><img src="https://cdn.liblaf.me/img/2023/2023-02-24T050729Z.png" alt="naive" tabindex="0" loading="lazy"><figcaption>naive</figcaption></figure><figure><img src="https://cdn.liblaf.me/img/2023/2023-02-24T050747Z.png" alt="shared_memory" tabindex="0" loading="lazy"><figcaption>shared_memory</figcaption></figure><figure><img src="https://cdn.liblaf.me/img/2023/2023-02-24T050806Z.png" alt="compare-x" tabindex="0" loading="lazy"><figcaption>compare-x</figcaption></figure><figure><img src="https://cdn.liblaf.me/img/2023/2023-02-24T050823Z.png" alt="compare-y" tabindex="0" loading="lazy"><figcaption>compare-y</figcaption></figure><h2 id="analysis" tabindex="-1"><a class="header-anchor" href="#analysis"><span>Analysis</span></a></h2><p>当 <code>block_size = 32 * 1</code> 时, <code>block_size</code> 过小, <code>grid</code> 数量过多, 导致调度产生的开销过大, 因此耗时较长.</p><p>在一些 <code>block_size</code> 取值处, 例如 <code>block_size = 32 * 16, 32 * 21</code> 等, <code>naive</code> 和 <code>shared_memory</code> 的性能都出现了较大幅度的跳变, 暂时想不出来为什么.</p><p>Shared Memory 带来的提升, 主要是通过增加内存访问时间以及 <code>__syncthreads</code> 开销, 以减少对同一元素重复调用 <code>calc</code> 方法. 当 <code>block_size</code> 较小时, <code>__syncthreads</code> 的开销较小, 因此 Shared Memory 能够带来一定的提升. 但随着 <code>block_size</code> 的增大, 同步的开销逐步增加, 导致 Shared Memory 带来的提升不明显, 甚至产生了负面影响.</p><p>事实上, 使用 Shared Memory 的实现对于每个 Thread 而言负载极不均衡. 位于边界的 Thread 需要进行数次 <code>calc</code>, 而位于 Block 内部的 Thread 只需要进行一次计算. 负载分配策略仍有优化空间. 除此之外, Shared Memory 实现使用了多次 <code>if</code>, 这也可能带来性能的损耗.</p><p>不难看出, Shared Memory 往往伴随着线程同步一起使用. 对于 CPU Bound 类型的程序, 通过划分较小的 <code>block_size</code>, 并使用 Shared Memory 优化, 应该能够有效提升程序性能. 而对于 Memory Bound 类型的程序, 使用 Shared Memory 减少重复计算显然得不偿失. 这时, Shared Memory 可能并不能带来性能的提升, 反而因为 Shared Memory 的访问速度限制使得程序性能更加糟糕.</p>',11),c=[r];function n(l,p){return a(),o("div",null,c)}const m=e(i,[["render",n],["__file","2022-04-26-exp6-cuda-并行策略.html.vue"]]),s=JSON.parse('{"path":"/2022/course-work/hpc/2022-04-26-exp6-cuda-%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5.html","title":"exp6: CUDA 并行策略","lang":"en-US","frontmatter":{"date":"2022-04-26T00:00:00.000Z","isOriginal":true,"category":["Course Work"],"tag":["CUDA","Introduction to High Performance Computing"],"title":"exp6: CUDA 并行策略","description":"Performance naivenaive shared_memoryshared_memory compare-xcompare-x compare-ycompare-y Analysis 当 block_size = 32 * 1 时, block_size 过小, grid 数量过多, 导致调度产生的开销过大, 因此耗时较长. 在一些 bloc...","head":[["meta",{"property":"og:url","content":"https://blog.liblaf.me/2022/course-work/hpc/2022-04-26-exp6-cuda-%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5.html"}],["meta",{"property":"og:site_name","content":"Blog"}],["meta",{"property":"og:title","content":"exp6: CUDA 并行策略"}],["meta",{"property":"og:description","content":"Performance naivenaive shared_memoryshared_memory compare-xcompare-x compare-ycompare-y Analysis 当 block_size = 32 * 1 时, block_size 过小, grid 数量过多, 导致调度产生的开销过大, 因此耗时较长. 在一些 bloc..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.liblaf.me/img/2023/2023-02-24T050729Z.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-03-03T09:57:39.000Z"}],["meta",{"property":"article:author","content":"liblaf"}],["meta",{"property":"article:tag","content":"CUDA"}],["meta",{"property":"article:tag","content":"Introduction to High Performance Computing"}],["meta",{"property":"article:published_time","content":"2022-04-26T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-03-03T09:57:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"exp6: CUDA 并行策略\\",\\"image\\":[\\"https://cdn.liblaf.me/img/2023/2023-02-24T050729Z.png\\",\\"https://cdn.liblaf.me/img/2023/2023-02-24T050747Z.png\\",\\"https://cdn.liblaf.me/img/2023/2023-02-24T050806Z.png\\",\\"https://cdn.liblaf.me/img/2023/2023-02-24T050823Z.png\\"],\\"datePublished\\":\\"2022-04-26T00:00:00.000Z\\",\\"dateModified\\":\\"2024-03-03T09:57:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"liblaf\\",\\"url\\":\\"https://liblaf.me\\",\\"email\\":\\"i@liblaf.me\\"}]}"]]},"headers":[{"level":2,"title":"Performance","slug":"performance","link":"#performance","children":[]},{"level":2,"title":"Analysis","slug":"analysis","link":"#analysis","children":[]}],"git":{"createdTime":1677217008000,"updatedTime":1709459859000,"contributors":[{"name":"liblaf","email":"30631553+liblaf@users.noreply.github.com","commits":4}]},"readingTime":{"minutes":1.45,"words":436},"filePathRelative":"2022/course-work/hpc/2022-04-26-exp6-cuda-并行策略.md","localizedDate":"April 26, 2022","excerpt":"<h2>Performance</h2>\\n<figure><img src=\\"https://cdn.liblaf.me/img/2023/2023-02-24T050729Z.png\\" alt=\\"naive\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>naive</figcaption></figure>\\n<figure><img src=\\"https://cdn.liblaf.me/img/2023/2023-02-24T050747Z.png\\" alt=\\"shared_memory\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>shared_memory</figcaption></figure>","autoDesc":true}');export{m as comp,s as data};
